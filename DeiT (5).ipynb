{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93cfc504-2ae8-4d64-956f-0f21fb17b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a92d80e-b467-46d6-ac5f-8ec71398eb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "from torch import nn\n",
    "from tensorflow.keras.models import Sequential\n",
    "from transformers import DeiTFeatureExtractor, DeiTModel\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55b60e43-2001-4b2c-9c8d-54d139bc6b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_path = r\"C:\\Users\\User\\Downloads\\Project Task 1\\train_labels.txt\"\n",
    "val_labels_path = r\"C:\\Users\\User\\Downloads\\Project Task 1\\val_labels.txt\"\n",
    "train_labels = pd.read_csv(train_labels_path, header=None).values.flatten()\n",
    "val_labels = pd.read_csv(val_labels_path, header=None).values.flatten()\n",
    "\n",
    "image_folder_train = r\"C:\\Users\\User\\Downloads\\Project Task 1\\train_data\"\n",
    "image_folder_val = r\"C:\\Users\\User\\Downloads\\Project Task 1\\val_data\"\n",
    "train_image_paths = [os.path.join(image_folder_train, img) for img in os.listdir(image_folder_train)]\n",
    "val_image_paths = [os.path.join(image_folder_val, img) for img in os.listdir(image_folder_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "569ccca0-4cf0-4480-91e4-603b49d5e0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\deit\\feature_extraction_deit.py:28: FutureWarning: The class DeiTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use DeiTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Some weights of DeiTModel were not initialized from the model checkpoint at facebook/deit-base-distilled-patch16-224 and are newly initialized: ['deit.pooler.dense.bias', 'deit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = DeiTFeatureExtractor.from_pretrained(\"facebook/deit-base-distilled-patch16-224\")\n",
    "deit_model = DeiTModel.from_pretrained(\"facebook/deit-base-distilled-patch16-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30c694f0-d7c5-4a7e-a47f-9010e8dd59ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels range: 1 - 60\n",
      "Validation labels range: 1 - 60\n"
     ]
    }
   ],
   "source": [
    "print(\"Train labels range:\", train_labels.min(), \"-\", train_labels.max())\n",
    "print(\"Validation labels range:\", val_labels.min(), \"-\", val_labels.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7724165e-a51b-4848-bfe6-552d9378214f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(np.unique(train_labels))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "781c743c-6843-4999-a716-68028f5aa2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "train_labels = encoder.fit_transform(train_labels)\n",
    "val_labels = encoder.transform(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a96f0c9c-6cf3-4632-b139-a206a8d807f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_images(image_paths):\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        inputs = feature_extractor(images=img, return_tensors=\"pt\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = deit_model(**inputs)\n",
    "            features = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "        images.append(features.squeeze()) \n",
    "\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ae417bb-d7ae-4224-bd2d-f9873e3694e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = load_and_preprocess_images(train_image_paths)\n",
    "val_features = load_and_preprocess_images(val_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "458c0576-e0c8-4823-95b0-f1aa8643f38c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': [1e-05, 5e-05, 0.0001, 0.0005],\n",
       " 'batch_size': [16, 32, 64],\n",
       " 'l2_value': [0.0001, 0.001, 0.005],\n",
       " 'dropout_rate': [0.3, 0.4, 0.5, 0.6],\n",
       " 'patience': [15, 20, 25]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rates = [1e-5, 5e-5, 1e-4, 5e-4]\n",
    "batch_sizes = [16, 32, 64]\n",
    "l2_values = [1e-4, 1e-3, 5e-3]\n",
    "dropout_rate = [0.3, 0.4, 0.5, 0.6]\n",
    "patience_values = [15, 20, 25]\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': learning_rates,\n",
    "    'batch_size': batch_sizes,\n",
    "    'l2_value': l2_values,\n",
    "    'dropout_rate': dropout_rate,\n",
    "    'patience': patience_values\n",
    "}\n",
    "grid = ParameterGrid(param_grid)\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "595272de-5f32-4b14-b7ee-02b7b21dfff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_value = 1e-4         \n",
    "learning_rate = 5e-5 \n",
    "batch_size = 32        \n",
    "dropout_rate = 0.3      \n",
    "patience = 25         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e37598-24b7-4781-90c3-fd8273d12560",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.0158 - loss: 5.0744 - val_accuracy: 0.0400 - val_loss: 4.1111\n",
      "Epoch 2/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0424 - loss: 4.5917 - val_accuracy: 0.0767 - val_loss: 3.9232\n",
      "Epoch 3/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0610 - loss: 4.3257 - val_accuracy: 0.1583 - val_loss: 3.6290\n",
      "Epoch 4/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0859 - loss: 4.1026 - val_accuracy: 0.2450 - val_loss: 3.3197\n",
      "Epoch 5/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.1051 - loss: 3.9011 - val_accuracy: 0.3367 - val_loss: 3.0678\n",
      "Epoch 6/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.1364 - loss: 3.6960 - val_accuracy: 0.3933 - val_loss: 2.8976\n",
      "Epoch 7/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.1556 - loss: 3.5419 - val_accuracy: 0.4517 - val_loss: 2.7813\n",
      "Epoch 8/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.1942 - loss: 3.3952 - val_accuracy: 0.4967 - val_loss: 2.6302\n",
      "Epoch 9/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.1977 - loss: 3.3159 - val_accuracy: 0.5050 - val_loss: 2.5628\n",
      "Epoch 10/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2189 - loss: 3.1879 - val_accuracy: 0.5667 - val_loss: 2.4581\n",
      "Epoch 11/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2383 - loss: 3.1546 - val_accuracy: 0.5533 - val_loss: 2.3961\n",
      "Epoch 12/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2788 - loss: 2.9495 - val_accuracy: 0.5983 - val_loss: 2.3197\n",
      "Epoch 13/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3013 - loss: 2.9116 - val_accuracy: 0.6133 - val_loss: 2.2435\n",
      "Epoch 14/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3081 - loss: 2.8498 - val_accuracy: 0.6183 - val_loss: 2.1943\n",
      "Epoch 15/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3190 - loss: 2.8083 - val_accuracy: 0.6550 - val_loss: 2.0457\n",
      "Epoch 16/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3378 - loss: 2.7672 - val_accuracy: 0.6950 - val_loss: 2.0037\n",
      "Epoch 17/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3572 - loss: 2.6421 - val_accuracy: 0.7033 - val_loss: 1.9393\n",
      "Epoch 18/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.3646 - loss: 2.6162 - val_accuracy: 0.7183 - val_loss: 1.9680\n",
      "Epoch 19/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3920 - loss: 2.5225 - val_accuracy: 0.7317 - val_loss: 1.8971\n",
      "Epoch 20/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3959 - loss: 2.4972 - val_accuracy: 0.7650 - val_loss: 1.7532\n",
      "Epoch 21/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4338 - loss: 2.3753 - val_accuracy: 0.7567 - val_loss: 1.7450\n",
      "Epoch 22/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4271 - loss: 2.3878 - val_accuracy: 0.7717 - val_loss: 1.7244\n",
      "Epoch 23/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4409 - loss: 2.3237 - val_accuracy: 0.7683 - val_loss: 1.7185\n",
      "Epoch 24/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4618 - loss: 2.2652 - val_accuracy: 0.8017 - val_loss: 1.6099\n",
      "Epoch 25/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4759 - loss: 2.2557 - val_accuracy: 0.7883 - val_loss: 1.5919\n",
      "Epoch 26/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4926 - loss: 2.1957 - val_accuracy: 0.8233 - val_loss: 1.5067\n",
      "Epoch 27/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4988 - loss: 2.1460 - val_accuracy: 0.8133 - val_loss: 1.5216\n",
      "Epoch 28/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5285 - loss: 2.1043 - val_accuracy: 0.8433 - val_loss: 1.4773\n",
      "Epoch 29/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5316 - loss: 2.0662 - val_accuracy: 0.8383 - val_loss: 1.4148\n",
      "Epoch 30/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5385 - loss: 2.0066 - val_accuracy: 0.8500 - val_loss: 1.4086\n",
      "Epoch 31/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5561 - loss: 1.9813 - val_accuracy: 0.8433 - val_loss: 1.3591\n",
      "Epoch 32/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5527 - loss: 1.9614 - val_accuracy: 0.8400 - val_loss: 1.3657\n",
      "Epoch 33/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5740 - loss: 1.8939 - val_accuracy: 0.8517 - val_loss: 1.3175\n",
      "Epoch 34/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5694 - loss: 1.8721 - val_accuracy: 0.8700 - val_loss: 1.2454\n",
      "Epoch 35/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5891 - loss: 1.8847 - val_accuracy: 0.8617 - val_loss: 1.2735\n",
      "Epoch 36/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6103 - loss: 1.7993 - val_accuracy: 0.8650 - val_loss: 1.1823\n",
      "Epoch 37/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5939 - loss: 1.7929 - val_accuracy: 0.8733 - val_loss: 1.1991\n",
      "Epoch 38/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6193 - loss: 1.7147 - val_accuracy: 0.8833 - val_loss: 1.1663\n",
      "Epoch 39/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6420 - loss: 1.6953 - val_accuracy: 0.9017 - val_loss: 1.1302\n",
      "Epoch 40/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6438 - loss: 1.6479 - val_accuracy: 0.8933 - val_loss: 1.1008\n",
      "Epoch 41/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6658 - loss: 1.6036 - val_accuracy: 0.8817 - val_loss: 1.0757\n",
      "Epoch 42/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6693 - loss: 1.5921 - val_accuracy: 0.8983 - val_loss: 1.0465\n",
      "Epoch 43/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6735 - loss: 1.5385 - val_accuracy: 0.8983 - val_loss: 1.0551\n",
      "Epoch 44/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6900 - loss: 1.5305 - val_accuracy: 0.8967 - val_loss: 1.0097\n",
      "Epoch 45/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6894 - loss: 1.4964 - val_accuracy: 0.9100 - val_loss: 0.9923\n",
      "Epoch 46/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6917 - loss: 1.4633 - val_accuracy: 0.9100 - val_loss: 0.9504\n",
      "Epoch 47/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7127 - loss: 1.4407 - val_accuracy: 0.9100 - val_loss: 0.9578\n",
      "Epoch 48/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6991 - loss: 1.4950 - val_accuracy: 0.9100 - val_loss: 0.9470\n",
      "Epoch 49/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7147 - loss: 1.3837 - val_accuracy: 0.9117 - val_loss: 0.8904\n",
      "Epoch 50/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7195 - loss: 1.3728 - val_accuracy: 0.9117 - val_loss: 0.8724\n",
      "Epoch 51/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7264 - loss: 1.3743 - val_accuracy: 0.9167 - val_loss: 0.8559\n",
      "Epoch 52/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7298 - loss: 1.3325 - val_accuracy: 0.9217 - val_loss: 0.8492\n",
      "Epoch 53/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7712 - loss: 1.2524 - val_accuracy: 0.9250 - val_loss: 0.8212\n",
      "Epoch 54/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7584 - loss: 1.2824 - val_accuracy: 0.9183 - val_loss: 0.8236\n",
      "Epoch 55/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7720 - loss: 1.2180 - val_accuracy: 0.9217 - val_loss: 0.7811\n",
      "Epoch 56/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7837 - loss: 1.1974 - val_accuracy: 0.9300 - val_loss: 0.7582\n",
      "Epoch 57/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7659 - loss: 1.1955 - val_accuracy: 0.9267 - val_loss: 0.7657\n",
      "Epoch 58/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7603 - loss: 1.2336 - val_accuracy: 0.9333 - val_loss: 0.7201\n",
      "Epoch 59/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7701 - loss: 1.1962 - val_accuracy: 0.9167 - val_loss: 0.7239\n",
      "Epoch 60/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7916 - loss: 1.1310 - val_accuracy: 0.9250 - val_loss: 0.7383\n",
      "Epoch 61/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7946 - loss: 1.1144 - val_accuracy: 0.9300 - val_loss: 0.7296\n",
      "Epoch 62/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7961 - loss: 1.1080 - val_accuracy: 0.9250 - val_loss: 0.6893\n",
      "Epoch 63/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8144 - loss: 1.0555 - val_accuracy: 0.9317 - val_loss: 0.6430\n",
      "Epoch 64/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8176 - loss: 1.0129 - val_accuracy: 0.9283 - val_loss: 0.6486\n",
      "Epoch 65/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8286 - loss: 1.0135 - val_accuracy: 0.9383 - val_loss: 0.6400\n",
      "Epoch 66/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8064 - loss: 1.0449 - val_accuracy: 0.9317 - val_loss: 0.6387\n",
      "Epoch 67/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8204 - loss: 1.0068 - val_accuracy: 0.9400 - val_loss: 0.6171\n",
      "Epoch 68/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8250 - loss: 0.9827 - val_accuracy: 0.9383 - val_loss: 0.6057\n",
      "Epoch 69/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8308 - loss: 0.9522 - val_accuracy: 0.9350 - val_loss: 0.6090\n",
      "Epoch 70/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8347 - loss: 0.9563 - val_accuracy: 0.9500 - val_loss: 0.5704\n",
      "Epoch 71/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8304 - loss: 0.9367 - val_accuracy: 0.9417 - val_loss: 0.5694\n",
      "Epoch 72/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8422 - loss: 0.8847 - val_accuracy: 0.9383 - val_loss: 0.5681\n",
      "Epoch 73/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8307 - loss: 0.9246 - val_accuracy: 0.9383 - val_loss: 0.5572\n",
      "Epoch 74/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8449 - loss: 0.9073 - val_accuracy: 0.9383 - val_loss: 0.5485\n",
      "Epoch 75/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8536 - loss: 0.8697 - val_accuracy: 0.9433 - val_loss: 0.5123\n",
      "Epoch 76/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8489 - loss: 0.8374 - val_accuracy: 0.9417 - val_loss: 0.5366\n",
      "Epoch 77/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8465 - loss: 0.8637 - val_accuracy: 0.9433 - val_loss: 0.5209\n",
      "Epoch 78/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8643 - loss: 0.8209 - val_accuracy: 0.9417 - val_loss: 0.4943\n",
      "Epoch 79/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8800 - loss: 0.7859 - val_accuracy: 0.9417 - val_loss: 0.4949\n",
      "Epoch 80/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8836 - loss: 0.7755 - val_accuracy: 0.9417 - val_loss: 0.4802\n",
      "Epoch 81/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8786 - loss: 0.7644 - val_accuracy: 0.9450 - val_loss: 0.4693\n",
      "Epoch 82/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8819 - loss: 0.7576 - val_accuracy: 0.9367 - val_loss: 0.4801\n",
      "Epoch 83/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8867 - loss: 0.7121 - val_accuracy: 0.9417 - val_loss: 0.4523\n",
      "Epoch 84/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8846 - loss: 0.7191 - val_accuracy: 0.9433 - val_loss: 0.4660\n",
      "Epoch 85/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8805 - loss: 0.7374 - val_accuracy: 0.9417 - val_loss: 0.4664\n",
      "Epoch 86/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8922 - loss: 0.7111 - val_accuracy: 0.9467 - val_loss: 0.4341\n",
      "Epoch 87/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8991 - loss: 0.6881 - val_accuracy: 0.9367 - val_loss: 0.4448\n",
      "Epoch 88/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8963 - loss: 0.6941 - val_accuracy: 0.9467 - val_loss: 0.4397\n",
      "Epoch 89/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9098 - loss: 0.6380 - val_accuracy: 0.9500 - val_loss: 0.4286\n",
      "Epoch 90/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8928 - loss: 0.6834 - val_accuracy: 0.9433 - val_loss: 0.4282\n",
      "Epoch 91/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9067 - loss: 0.6598 - val_accuracy: 0.9433 - val_loss: 0.4057\n",
      "Epoch 92/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9026 - loss: 0.6421 - val_accuracy: 0.9533 - val_loss: 0.4107\n",
      "Epoch 93/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8935 - loss: 0.6445 - val_accuracy: 0.9483 - val_loss: 0.4036\n",
      "Epoch 94/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8950 - loss: 0.6331 - val_accuracy: 0.9533 - val_loss: 0.3890\n",
      "Epoch 95/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9091 - loss: 0.5950 - val_accuracy: 0.9533 - val_loss: 0.3812\n",
      "Epoch 96/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9058 - loss: 0.6134 - val_accuracy: 0.9467 - val_loss: 0.3850\n",
      "Epoch 97/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8947 - loss: 0.6279 - val_accuracy: 0.9433 - val_loss: 0.3860\n",
      "Epoch 98/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9063 - loss: 0.5894 - val_accuracy: 0.9467 - val_loss: 0.3844\n",
      "Epoch 99/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9049 - loss: 0.5756 - val_accuracy: 0.9500 - val_loss: 0.3748\n",
      "Epoch 100/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9159 - loss: 0.5861 - val_accuracy: 0.9467 - val_loss: 0.4050\n",
      "Epoch 101/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9208 - loss: 0.5693 - val_accuracy: 0.9483 - val_loss: 0.3611\n",
      "Epoch 102/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9334 - loss: 0.5300 - val_accuracy: 0.9500 - val_loss: 0.3624\n",
      "Epoch 103/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9231 - loss: 0.5212 - val_accuracy: 0.9500 - val_loss: 0.3469\n",
      "Epoch 104/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9222 - loss: 0.5391 - val_accuracy: 0.9383 - val_loss: 0.3824\n",
      "Epoch 105/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9339 - loss: 0.4957 - val_accuracy: 0.9517 - val_loss: 0.3556\n",
      "Epoch 106/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9233 - loss: 0.5210 - val_accuracy: 0.9533 - val_loss: 0.3346\n",
      "Epoch 107/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9252 - loss: 0.5127 - val_accuracy: 0.9400 - val_loss: 0.3521\n",
      "Epoch 108/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9331 - loss: 0.4968 - val_accuracy: 0.9433 - val_loss: 0.3523\n",
      "Epoch 109/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9368 - loss: 0.4891 - val_accuracy: 0.9533 - val_loss: 0.3163\n",
      "Epoch 110/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9283 - loss: 0.4737 - val_accuracy: 0.9450 - val_loss: 0.3339\n",
      "Epoch 111/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9291 - loss: 0.4882 - val_accuracy: 0.9517 - val_loss: 0.3173\n",
      "Epoch 112/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9327 - loss: 0.4829 - val_accuracy: 0.9450 - val_loss: 0.3334\n",
      "Epoch 113/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9279 - loss: 0.4710 - val_accuracy: 0.9483 - val_loss: 0.3197\n",
      "Epoch 114/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9379 - loss: 0.4521 - val_accuracy: 0.9433 - val_loss: 0.3278\n",
      "Epoch 115/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9473 - loss: 0.4271 - val_accuracy: 0.9583 - val_loss: 0.3094\n",
      "Epoch 116/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9371 - loss: 0.4781 - val_accuracy: 0.9467 - val_loss: 0.3152\n",
      "Epoch 117/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9400 - loss: 0.4428 - val_accuracy: 0.9467 - val_loss: 0.3139\n",
      "Epoch 118/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9269 - loss: 0.4678 - val_accuracy: 0.9517 - val_loss: 0.3093\n",
      "Epoch 119/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9406 - loss: 0.4337 - val_accuracy: 0.9483 - val_loss: 0.3032\n",
      "Epoch 120/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9498 - loss: 0.4076 - val_accuracy: 0.9500 - val_loss: 0.2976\n",
      "Epoch 121/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9473 - loss: 0.4011 - val_accuracy: 0.9500 - val_loss: 0.3120\n",
      "Epoch 122/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9511 - loss: 0.3893 - val_accuracy: 0.9517 - val_loss: 0.3023\n",
      "Epoch 123/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9396 - loss: 0.4200 - val_accuracy: 0.9550 - val_loss: 0.2915\n",
      "Epoch 124/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9582 - loss: 0.3760 - val_accuracy: 0.9483 - val_loss: 0.2994\n",
      "Epoch 125/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9518 - loss: 0.3751 - val_accuracy: 0.9500 - val_loss: 0.2853\n",
      "Epoch 126/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9589 - loss: 0.3621 - val_accuracy: 0.9533 - val_loss: 0.2759\n",
      "Epoch 127/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9548 - loss: 0.3806 - val_accuracy: 0.9567 - val_loss: 0.2835\n",
      "Epoch 128/500\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9395 - loss: 0.3975 - val_accuracy: 0.9600 - val_loss: 0.2689\n",
      "Epoch 129/500\n",
      "\u001b[1m 7/94\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9731 - loss: 0.3359 "
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    layers.Input(shape=(train_features.shape[1],)), \n",
    "    \n",
    "    layers.Reshape((train_features.shape[1], 1)), \n",
    "    \n",
    "    layers.Conv1D(8, 2, activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_value)),\n",
    "    layers.MaxPooling1D(2),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(l2_value)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(dropout_rate), \n",
    "    \n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(l2_value)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(dropout_rate + 0.1),\n",
    "    \n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(l2_value)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(dropout_rate + 0.2), \n",
    "    \n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=patience, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_features, train_labels,\n",
    "    epochs=500,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(val_features, val_labels),\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "val_accuracy = max(history.history['val_accuracy'])\n",
    "\n",
    "train_losses = history.history['loss']\n",
    "val_losses = history.history['val_loss']\n",
    "train_accuracies = history.history['accuracy']\n",
    "val_accuracies = history.history['val_accuracy']\n",
    "\n",
    "best_accuracy = val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e786141-7b96-4243-8be1-7de7b8b15128",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_weights.weights.h5')\n",
    "print(\"Model weights saved to 'model_weights.weights.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d04970b-34b4-477f-9296-de745ef15996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training and validation losses\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(np.arange(1, len(train_losses) + 1), train_losses, label='Train Loss')\n",
    "plt.plot(np.arange(1, len(val_losses) + 1), val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train Loss vs Val Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plotting training and validation accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(np.arange(1, len(train_accuracies) + 1), train_accuracies, label='Train Accuracy')\n",
    "plt.plot(np.arange(1, len(val_accuracies) + 1), val_accuracies, label='Val Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Train Accuracy vs Val Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print the best accuracy achieved with the fine-tuned parameters\n",
    "print(\"Fine-tuned Parameters:\", fine_tuned_params)\n",
    "print(\"Best Validation Accuracy:\", best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad19275-4b64-45fa-98ed-5410e827d67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_single_image(image_path):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = feature_extractor(images=img, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = deit_model(**inputs)\n",
    "        features = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cd79f2-5508-43a8-aa79-689d718aeaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = r\"C:\\Users\\User\\Downloads\\Project Task 1\\val_data\\8_image_03427.jpg\"\n",
    "test_image_features = load_and_preprocess_single_image(test_image_path)\n",
    "\n",
    "prediction = model.predict(test_image_features)\n",
    "\n",
    "predicted_class = np.argmax(prediction, axis=1)\n",
    "\n",
    "# Print predicted class\n",
    "print(f\"Predicted class for the test image: {predicted_class[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8ba5c9-5778-4285-b079-c37db61a9f17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
